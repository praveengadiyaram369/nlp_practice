{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "seq_2_seq_modelling.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "actual-turkey"
      },
      "source": [
        "https://keras.io/examples/nlp/lstm_seq2seq/"
      ],
      "id": "actual-turkey"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aggregate-capital"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "id": "aggregate-capital",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efficient-divide"
      },
      "source": [
        "with open('fra.txt', 'r') as f:\n",
        "    text_data = f.read().split('\\n')\n",
        "    \n",
        "text_data = text_data[:10000]"
      ],
      "id": "efficient-divide",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stuffed-brighton"
      },
      "source": [
        "english_sentences = []\n",
        "french_sentences = []\n",
        "english_characters = set()\n",
        "french_characters = set()\n",
        "\n",
        "for idx, val in enumerate(text_data):\n",
        "    eng_data, fre_data, _ = val.split('\\t')\n",
        "    english_sentences.append(eng_data)\n",
        "    for char in eng_data:\n",
        "        if char not in english_characters:\n",
        "            english_characters.add(char)\n",
        "    \n",
        "    fre_data = '\\t' + fre_data + '\\n'\n",
        "    french_sentences.append(fre_data)\n",
        "    for char in fre_data:\n",
        "        if char not in french_characters:\n",
        "            french_characters.add(char)"
      ],
      "id": "stuffed-brighton",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dedicated-projector"
      },
      "source": [
        "encoder_char_len = len(english_characters)\n",
        "decoder_char_len = len(french_characters)\n",
        "\n",
        "encoder_chars = sorted(english_characters)\n",
        "decoder_chars = sorted(french_characters)\n",
        "\n",
        "max_encoder_sequence_len = max([len(seq) for seq in english_sentences])\n",
        "max_decoder_sequence_len = max([len(seq) for seq in french_sentences])"
      ],
      "id": "dedicated-projector",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "racial-literature"
      },
      "source": [
        "input_encoder_data = np.zeros((len(english_sentences), max_encoder_sequence_len, encoder_char_len), dtype='float32')\n",
        "input_decoder_data = np.zeros((len(french_sentences), max_decoder_sequence_len, decoder_char_len), dtype='float32')\n",
        "target_decoder_data = np.zeros((len(french_sentences), max_decoder_sequence_len, decoder_char_len), dtype='float32')"
      ],
      "id": "racial-literature",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "circular-murder"
      },
      "source": [
        "encoder_input_index = dict([(char, idx) for idx, char in enumerate(encoder_chars)])\n",
        "decoder_input_index = dict([(char, idx) for idx, char in enumerate(decoder_chars)])"
      ],
      "id": "circular-murder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moral-blast"
      },
      "source": [
        "assert len(english_sentences) == len(french_sentences)"
      ],
      "id": "moral-blast",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rural-junction"
      },
      "source": [
        "sentence_break_space = ' '"
      ],
      "id": "rural-junction",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "breathing-borough"
      },
      "source": [
        "for row, (encoder_data, decoder_data) in enumerate(zip(english_sentences, french_sentences)):\n",
        "    \n",
        "    for col, char in enumerate(encoder_data):\n",
        "        input_encoder_data[row, col, encoder_input_index[char]] = 1.0\n",
        "    input_encoder_data[row, col+1:, encoder_input_index[sentence_break_space]] = 0\n",
        "    \n",
        "    for col, char in enumerate(decoder_data):\n",
        "        input_decoder_data[row, col, decoder_input_index[char]] = 1.0\n",
        "        \n",
        "        if col > 0:\n",
        "            target_decoder_data[row, col-1, decoder_input_index[char]] = 1.0\n",
        "            \n",
        "    input_decoder_data[row, col+1:, decoder_input_index[sentence_break_space]] = 1.0\n",
        "    target_decoder_data[row, col:, decoder_input_index[sentence_break_space]] = 1.0"
      ],
      "id": "breathing-borough",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olympic-mailman",
        "outputId": "b498643e-5f44-4b31-e407-29ab7460e062"
      },
      "source": [
        "encoder_inputs = tf.keras.Input(shape=(None, encoder_char_len))\n",
        "encoder_lstm = tf.keras.layers.LSTM(256, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = tf.keras.Input(shape=(None, decoder_char_len))\n",
        "decoder_lstm = tf.keras.layers.LSTM(256, return_state=True, return_sequences=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state= encoder_states)\n",
        "\n",
        "decoder_dense = tf.keras.layers.Dense(decoder_char_len, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()"
      ],
      "id": "olympic-mailman",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 71)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 93)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 335872      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  358400      input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 93)     23901       lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 718,173\n",
            "Trainable params: 718,173\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afraid-underground",
        "outputId": "976427ab-8026-4259-e194-13bb3f9f52c6"
      },
      "source": [
        "model.compile(optimizer='rmsprop', metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "\n",
        "model.fit([input_encoder_data, input_decoder_data], target_decoder_data, batch_size=64, epochs=100, validation_split=0.2)"
      ],
      "id": "afraid-underground",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 37s 47ms/step - loss: 1.5104 - accuracy: 0.7019 - val_loss: 1.0459 - val_accuracy: 0.7101\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.8803 - accuracy: 0.7602 - val_loss: 0.8359 - val_accuracy: 0.7726\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.7139 - accuracy: 0.8053 - val_loss: 0.7176 - val_accuracy: 0.7948\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.5973 - accuracy: 0.8272 - val_loss: 0.6315 - val_accuracy: 0.8161\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.5390 - accuracy: 0.8427 - val_loss: 0.5983 - val_accuracy: 0.8238\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.4978 - accuracy: 0.8538 - val_loss: 0.5665 - val_accuracy: 0.8337\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.4731 - accuracy: 0.8600 - val_loss: 0.5404 - val_accuracy: 0.8413\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.4446 - accuracy: 0.8686 - val_loss: 0.5248 - val_accuracy: 0.8463\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.4262 - accuracy: 0.8732 - val_loss: 0.5129 - val_accuracy: 0.8489\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.4044 - accuracy: 0.8795 - val_loss: 0.4997 - val_accuracy: 0.8527\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.3884 - accuracy: 0.8837 - val_loss: 0.4894 - val_accuracy: 0.8570\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.3650 - accuracy: 0.8906 - val_loss: 0.4792 - val_accuracy: 0.8585\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.3571 - accuracy: 0.8928 - val_loss: 0.4702 - val_accuracy: 0.8616\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.3449 - accuracy: 0.8959 - val_loss: 0.4677 - val_accuracy: 0.8621\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3300 - accuracy: 0.9001 - val_loss: 0.4642 - val_accuracy: 0.8649\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.3174 - accuracy: 0.9043 - val_loss: 0.4574 - val_accuracy: 0.8652\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.3035 - accuracy: 0.9080 - val_loss: 0.4534 - val_accuracy: 0.8676\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2939 - accuracy: 0.9117 - val_loss: 0.4519 - val_accuracy: 0.8691\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2817 - accuracy: 0.9145 - val_loss: 0.4487 - val_accuracy: 0.8705\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2745 - accuracy: 0.9170 - val_loss: 0.4510 - val_accuracy: 0.8704\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2632 - accuracy: 0.9199 - val_loss: 0.4480 - val_accuracy: 0.8721\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2545 - accuracy: 0.9229 - val_loss: 0.4509 - val_accuracy: 0.8712\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2453 - accuracy: 0.9251 - val_loss: 0.4490 - val_accuracy: 0.8727\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2378 - accuracy: 0.9280 - val_loss: 0.4525 - val_accuracy: 0.8728\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2281 - accuracy: 0.9304 - val_loss: 0.4538 - val_accuracy: 0.8736\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2219 - accuracy: 0.9324 - val_loss: 0.4526 - val_accuracy: 0.8749\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2138 - accuracy: 0.9347 - val_loss: 0.4577 - val_accuracy: 0.8740\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2075 - accuracy: 0.9368 - val_loss: 0.4572 - val_accuracy: 0.8745\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2028 - accuracy: 0.9380 - val_loss: 0.4607 - val_accuracy: 0.8748\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1947 - accuracy: 0.9408 - val_loss: 0.4685 - val_accuracy: 0.8744\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1877 - accuracy: 0.9428 - val_loss: 0.4659 - val_accuracy: 0.8759\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1835 - accuracy: 0.9440 - val_loss: 0.4700 - val_accuracy: 0.8748\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1780 - accuracy: 0.9458 - val_loss: 0.4754 - val_accuracy: 0.8761\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1706 - accuracy: 0.9481 - val_loss: 0.4864 - val_accuracy: 0.8743\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1664 - accuracy: 0.9490 - val_loss: 0.4867 - val_accuracy: 0.8744\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1626 - accuracy: 0.9506 - val_loss: 0.4885 - val_accuracy: 0.8746\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1579 - accuracy: 0.9517 - val_loss: 0.4867 - val_accuracy: 0.8753\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1532 - accuracy: 0.9534 - val_loss: 0.4950 - val_accuracy: 0.8749\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1493 - accuracy: 0.9542 - val_loss: 0.4981 - val_accuracy: 0.8755\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1444 - accuracy: 0.9556 - val_loss: 0.5077 - val_accuracy: 0.8747\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1421 - accuracy: 0.9563 - val_loss: 0.5059 - val_accuracy: 0.8758\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1375 - accuracy: 0.9578 - val_loss: 0.5125 - val_accuracy: 0.8751\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1336 - accuracy: 0.9587 - val_loss: 0.5233 - val_accuracy: 0.8756\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1296 - accuracy: 0.9602 - val_loss: 0.5223 - val_accuracy: 0.8748\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1273 - accuracy: 0.9610 - val_loss: 0.5294 - val_accuracy: 0.8743\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1231 - accuracy: 0.9624 - val_loss: 0.5382 - val_accuracy: 0.8733\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1217 - accuracy: 0.9625 - val_loss: 0.5383 - val_accuracy: 0.8752\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1170 - accuracy: 0.9637 - val_loss: 0.5391 - val_accuracy: 0.8751\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1160 - accuracy: 0.9643 - val_loss: 0.5456 - val_accuracy: 0.8744\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1132 - accuracy: 0.9649 - val_loss: 0.5505 - val_accuracy: 0.8751\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1095 - accuracy: 0.9659 - val_loss: 0.5554 - val_accuracy: 0.8748\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1066 - accuracy: 0.9671 - val_loss: 0.5571 - val_accuracy: 0.8746\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1048 - accuracy: 0.9673 - val_loss: 0.5630 - val_accuracy: 0.8747\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1020 - accuracy: 0.9683 - val_loss: 0.5667 - val_accuracy: 0.8751\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1000 - accuracy: 0.9688 - val_loss: 0.5726 - val_accuracy: 0.8752\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0984 - accuracy: 0.9692 - val_loss: 0.5797 - val_accuracy: 0.8737\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0958 - accuracy: 0.9698 - val_loss: 0.5830 - val_accuracy: 0.8747\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0943 - accuracy: 0.9703 - val_loss: 0.5874 - val_accuracy: 0.8746\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0928 - accuracy: 0.9706 - val_loss: 0.5941 - val_accuracy: 0.8746\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0904 - accuracy: 0.9711 - val_loss: 0.5935 - val_accuracy: 0.8744\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0891 - accuracy: 0.9719 - val_loss: 0.6038 - val_accuracy: 0.8739\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0860 - accuracy: 0.9726 - val_loss: 0.6036 - val_accuracy: 0.8739\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0851 - accuracy: 0.9728 - val_loss: 0.6081 - val_accuracy: 0.8735\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0831 - accuracy: 0.9736 - val_loss: 0.6116 - val_accuracy: 0.8746\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0808 - accuracy: 0.9741 - val_loss: 0.6175 - val_accuracy: 0.8738\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0793 - accuracy: 0.9745 - val_loss: 0.6171 - val_accuracy: 0.8741\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0789 - accuracy: 0.9747 - val_loss: 0.6264 - val_accuracy: 0.8741\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0769 - accuracy: 0.9753 - val_loss: 0.6284 - val_accuracy: 0.8737\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0756 - accuracy: 0.9755 - val_loss: 0.6351 - val_accuracy: 0.8728\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0741 - accuracy: 0.9760 - val_loss: 0.6390 - val_accuracy: 0.8738\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0734 - accuracy: 0.9761 - val_loss: 0.6435 - val_accuracy: 0.8729\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0716 - accuracy: 0.9767 - val_loss: 0.6477 - val_accuracy: 0.8740\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0701 - accuracy: 0.9773 - val_loss: 0.6442 - val_accuracy: 0.8739\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0688 - accuracy: 0.9773 - val_loss: 0.6572 - val_accuracy: 0.8725\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0677 - accuracy: 0.9777 - val_loss: 0.6509 - val_accuracy: 0.8748\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0666 - accuracy: 0.9780 - val_loss: 0.6616 - val_accuracy: 0.8744\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0656 - accuracy: 0.9784 - val_loss: 0.6603 - val_accuracy: 0.8736\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0644 - accuracy: 0.9787 - val_loss: 0.6675 - val_accuracy: 0.8735\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0638 - accuracy: 0.9787 - val_loss: 0.6714 - val_accuracy: 0.8732\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0629 - accuracy: 0.9790 - val_loss: 0.6793 - val_accuracy: 0.8729\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0612 - accuracy: 0.9794 - val_loss: 0.6768 - val_accuracy: 0.8732\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0602 - accuracy: 0.9796 - val_loss: 0.6849 - val_accuracy: 0.8732\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0602 - accuracy: 0.9797 - val_loss: 0.6838 - val_accuracy: 0.8726\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0584 - accuracy: 0.9804 - val_loss: 0.6895 - val_accuracy: 0.8736\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0577 - accuracy: 0.9808 - val_loss: 0.6925 - val_accuracy: 0.8732\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0572 - accuracy: 0.9806 - val_loss: 0.6915 - val_accuracy: 0.8732\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0555 - accuracy: 0.9814 - val_loss: 0.6997 - val_accuracy: 0.8732\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0550 - accuracy: 0.9813 - val_loss: 0.6999 - val_accuracy: 0.8731\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0541 - accuracy: 0.9813 - val_loss: 0.7012 - val_accuracy: 0.8734\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0535 - accuracy: 0.9819 - val_loss: 0.7060 - val_accuracy: 0.8733\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0525 - accuracy: 0.9818 - val_loss: 0.7147 - val_accuracy: 0.8733\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0521 - accuracy: 0.9818 - val_loss: 0.7093 - val_accuracy: 0.8734\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0511 - accuracy: 0.9821 - val_loss: 0.7159 - val_accuracy: 0.8727\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0507 - accuracy: 0.9822 - val_loss: 0.7184 - val_accuracy: 0.8731\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0499 - accuracy: 0.9829 - val_loss: 0.7221 - val_accuracy: 0.8732\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.0486 - accuracy: 0.9832 - val_loss: 0.7293 - val_accuracy: 0.8731\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0487 - accuracy: 0.9829 - val_loss: 0.7373 - val_accuracy: 0.8725\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0475 - accuracy: 0.9837 - val_loss: 0.7299 - val_accuracy: 0.8736\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0470 - accuracy: 0.9836 - val_loss: 0.7347 - val_accuracy: 0.8727\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0467 - accuracy: 0.9836 - val_loss: 0.7356 - val_accuracy: 0.8729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0306c06350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqOevs4FZnyX"
      },
      "source": [
        "reverse_encoder_input_index = dict([(idx, char) for char, idx in encoder_input_index.items()])\n",
        "reverse_decoder_input_index = dict([(idx, char) for char, idx in decoder_input_index.items()])"
      ],
      "id": "yqOevs4FZnyX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pF_d5t85Zw5"
      },
      "source": [
        "encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = tf.keras.Input(shape=(256,), name='input_3')\n",
        "decoder_state_input_c = tf.keras.Input(shape=(256,), name='input_4')\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, decoder_state_output_h, decoder_state_output_c = decoder_lstm(decoder_inputs, initial_state= decoder_states_inputs)\n",
        "\n",
        "decoder_output_states = [decoder_state_output_h, decoder_state_output_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = tf.keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_output_states)"
      ],
      "id": "_pF_d5t85Zw5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDlPRGVpTBvX"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "\n",
        "  encoder_context_out = encoder_model.predict(input_seq)\n",
        "\n",
        "  target_seq = np.zeros((1, 1, decoder_char_len))\n",
        "  target_seq[0, 0, decoder_input_index['\\t']] = 1.0\n",
        "\n",
        "  decoded_sentence = ''\n",
        "  stop_condition = False\n",
        "\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + encoder_context_out)\n",
        "\n",
        "    sample_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = reverse_decoder_input_index[sample_token_index]\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    if sampled_char == '\\n' or len(decoded_sentence) > max_decoder_sequence_len:\n",
        "      stop_condition = True\n",
        "\n",
        "    target_seq = np.zeros((1, 1, decoder_char_len))\n",
        "    target_seq[0, 0, sample_token_index] = 1.0\n",
        "\n",
        "    encoder_context_out = [h, c]\n",
        "    \n",
        "  return decoded_sentence\n"
      ],
      "id": "LDlPRGVpTBvX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmRmNQCAIUJM",
        "outputId": "186e35ad-a379-43b3-bc88-ba5ee580e54a"
      },
      "source": [
        "for idx in range(20):\n",
        "\n",
        "  eng_sent = english_sentences[idx]\n",
        "  print(f'English Sentence: {eng_sent}')\n",
        "\n",
        "  input_seq = input_encoder_data[idx:idx+1]\n",
        "  #print(input_seq)\n",
        "  french_sent = decode_sequence(input_seq)\n",
        "  print(f'Translated French Sentence: {french_sent}')"
      ],
      "id": "zmRmNQCAIUJM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Sentence: Go.\n",
            "Translated French Sentence: Va !\n",
            "\n",
            "English Sentence: Go.\n",
            "Translated French Sentence: Va !\n",
            "\n",
            "English Sentence: Go.\n",
            "Translated French Sentence: Va !\n",
            "\n",
            "English Sentence: Hi.\n",
            "Translated French Sentence: Salut !\n",
            "\n",
            "English Sentence: Hi.\n",
            "Translated French Sentence: Salut !\n",
            "\n",
            "English Sentence: Run!\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run!\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run!\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run!\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run!\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run!\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run!\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run!\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run.\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run.\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run.\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run.\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run.\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run.\n",
            "Translated French Sentence: Fuyons !\n",
            "\n",
            "English Sentence: Run.\n",
            "Translated French Sentence: Fuyons !\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}